from pyspark.sql import SparkSession, DataFrame
from pyspark.sql.types import Row
from pyspark.sql.functions import col


def main(spark):  
  
  # Read Plants Files Generated by datagen
  df_plants = spark.read.parquet("/user/datagen/hdfs/industry/plant/")
  df_plants.printSchema()
  df_plants.show(1)
  
  # Read Sensor Files generated by datagen
  df_sensors = spark.read.parquet("/user/datagen/hdfs/industry/sensor/")
  df_sensors.printSchema()
  df_sensors.show(1)
  
  # Filter to have only sensor of type speed and located in France
  df_france_speed_sensors = df_sensors.join(df_plants, df_sensors.plant_id == df_plants.plant_id)\
  .filter(col("sensor_type")=='speed')\
  .filter(col("country")=='France')\
  .drop(df_sensors.plant_id)
  
  df_france_speed_sensors.show()
  
  # Read Sensors Data
  df_sensors_data = spark.read.parquet("/user/datagen/hdfs/industry/sensor_data/")
  df_sensors_data.printSchema()
  df_sensors_data.show(1)
  
  # Join to get value of france speed sensors
  df_france_speed_sensors_data = df_france_speed_sensors\
  .join(df_sensors_data, df_france_speed_sensors.sensor_id == df_sensors_data.sensor_id)\
  .drop(df_france_speed_sensors.sensor_id)
  
  df_france_speed_sensors_data.show()
  
  # Finally write this data to HDFS
  df_france_speed_sensors_data.write.mode("append")\
  .parquet("/user/datagen/hdfs/industry/sensor_french_speed_data/")
  
  
if __name__ == '__main__':
  # Create a Spark Session
  spark = SparkSession\
  .builder\
  .appName("PlantsAndSensors")\
  .getOrCreate()
  
  main(spark)
  
  